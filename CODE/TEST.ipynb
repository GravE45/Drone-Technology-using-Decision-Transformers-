{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12])\n",
      "torch.Size([2, 12, 4])\n",
      "torch.Size([2, 12, 2])\n",
      "torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Example trajectories\n",
    "trajectories = [\n",
    "    [\n",
    "        ([50, 950], [950, 50], (4, 2), 50, [150, 950], [950, 150], False),\n",
    "        ([150, 950], [950, 150], (4, 2), 30, [250, 950], [950, 250], False),\n",
    "        ([250, 950], [950, 250], (0, 3), 0, [250, 950], [850, 250], False),\n",
    "        ([250, 950], [850, 250], (1, 1), 20, [250, 850], [850, 150], False),\n",
    "        ([250, 850], [850, 150], (0, 4), 0, [250, 850], [950, 150], False),\n",
    "        ([250, 850], [950, 150], (1, 1), 20, [250, 750], [950, 50], False),\n",
    "        ([250, 750], [950, 50], (4, 1), -100, [350, 750], [950, 50], False),\n",
    "        ([350, 750], [950, 50], (1, 1), -80, [350, 650], [950, 50], False),\n",
    "        ([350, 650], [950, 50], (4, 0), 10, [450, 650], [950, 50], False),\n",
    "        ([450, 650], [950, 50], (4, 2), 30, [550, 650], [950, 150], False),\n",
    "        ([550, 650], [950, 150], (2, 4), -70, [550, 750], [950, 150], False),\n",
    "        ([550, 750], [950, 150], (0, 3), 0, [550, 750], [850, 150], False),\n",
    "        \n",
    "        # Add more steps...\n",
    "    ],[\n",
    "        ([50, 950], [950, 50], (4, 2), 50, [150, 950], [950, 150], False),\n",
    "        ([150, 950], [950, 150], (4, 2), 30, [250, 950], [950, 250], False),\n",
    "        ([250, 950], [950, 250], (0, 3), 0, [250, 950], [850, 250], False),\n",
    "        ([250, 950], [850, 250], (1, 1), 20, [250, 850], [850, 150], False),\n",
    "        ([250, 850], [850, 150], (0, 4), 0, [250, 850], [950, 150], False),\n",
    "        ([250, 850], [950, 150], (1, 1), 20, [250, 750], [950, 50], False),\n",
    "        ([250, 750], [950, 50], (4, 1), -100, [350, 750], [950, 50], False),\n",
    "        ([350, 750], [950, 50], (1, 1), -80, [350, 650], [950, 50], False),\n",
    "        ([350, 650], [950, 50], (4, 0), 10, [450, 650], [950, 50], False),\n",
    "        ([450, 650], [950, 50], (4, 2), 30, [550, 650], [950, 150], False),\n",
    "        ([550, 650], [950, 150], (2, 4), -70, [550, 750], [950, 150], False),\n",
    "        ([550, 750], [950, 150], (0, 3), 0, [550, 750], [850, 150], False),\n",
    "    ]\n",
    "    # Add more trajectories...\n",
    "]\n",
    "# Let's read the content of the 'data.txt' file and store it in a variable.\n",
    "# with open('data_1.json', 'r') as file:\n",
    "#     json_data = json.load(file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_trajectories(trajectories):\n",
    "    returns, states, actions, timesteps = [], [], [], []\n",
    "    for traj in trajectories:\n",
    "        traj_returns = []\n",
    "        traj_states = []\n",
    "        traj_actions = []\n",
    "        traj_timesteps = []\n",
    "        for t, step in enumerate(traj):\n",
    "            state_uav1, state_uav2, action, reward, next_state_uav1, next_state_uav2, done = step\n",
    "            state = state_uav1 + state_uav2\n",
    "            traj_returns.append(reward)\n",
    "            traj_states.append(state)\n",
    "            traj_actions.append(list(action))\n",
    "            traj_timesteps.append(t)  # Generate timesteps as a sequence of integers\n",
    "        returns.append(traj_returns)\n",
    "        states.append(traj_states)\n",
    "        actions.append(traj_actions)\n",
    "        timesteps.append(traj_timesteps)\n",
    "    return np.array(returns), np.array(states), np.array(actions), np.array(timesteps)\n",
    "\n",
    "returns, states, actions, timesteps = preprocess_trajectories(trajectories)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "returns_tensor = torch.tensor(returns, dtype=torch.float32)\n",
    "states_tensor = torch.tensor(states, dtype=torch.float32)\n",
    "actions_tensor = torch.tensor(actions, dtype=torch.float32)\n",
    "timesteps_tensor = torch.tensor(timesteps, dtype=torch.float32)\n",
    "\n",
    "print(returns_tensor.shape)  # Expected: (num_trajectories, num_steps)\n",
    "print(states_tensor.shape)  # Expected: (num_trajectories, num_steps, state_dim)\n",
    "print(actions_tensor.shape)  # Expected: (num_trajectories, num_steps, action_dim)\n",
    "print(timesteps_tensor.shape)  # Expected: (num_trajectories, num_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import GPT2Model, GPT2Config\n",
    "\n",
    "class DecisionTransformer(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_dim, max_length=50):\n",
    "        super(DecisionTransformer, self).__init__()\n",
    "        config = GPT2Config(vocab_size=1, n_positions=max_length, n_embd=hidden_dim, n_layer=4, n_head=8)\n",
    "        self.transformer = GPT2Model(config)\n",
    "        \n",
    "        # Embedding layers\n",
    "        self.embed_t = nn.Embedding(max_length, hidden_dim)\n",
    "        self.state_emb = nn.Linear(state_dim, hidden_dim)\n",
    "        self.action_emb = nn.Linear(action_dim, hidden_dim)\n",
    "        self.reward_emb = nn.Linear(1, hidden_dim)\n",
    "        \n",
    "        self.predict_action = nn.Linear(hidden_dim, action_dim)\n",
    "        \n",
    "    def forward(self, returns, states, actions, timesteps):\n",
    "        pos_embedding = self.embed_t(timesteps.long())\n",
    "        s_embedding = self.state_emb(states) + pos_embedding\n",
    "        a_embedding = self.action_emb(actions) + pos_embedding\n",
    "        R_embedding = self.reward_emb(returns.unsqueeze(-1)) + pos_embedding\n",
    "        \n",
    "        # Interleave tokens as (R_1, s_1, a_1, ..., R_K, s_K)\n",
    "        input_embeds = torch.cat((R_embedding.unsqueeze(1), s_embedding.unsqueeze(1), a_embedding.unsqueeze(1)), dim=1).view(s_embedding.size(0), -1, s_embedding.size(-1))\n",
    "        \n",
    "        # Debugging print statements\n",
    "        print(f\"input_embeds shape: {input_embeds.shape}\")\n",
    "        \n",
    "        # Use transformer to get hidden states\n",
    "        transformer_outputs = self.transformer(inputs_embeds=input_embeds)\n",
    "        hidden_states = transformer_outputs.last_hidden_state\n",
    "        \n",
    "        print(f\"hidden_states shape: {hidden_states.shape}\")\n",
    "        \n",
    "        # Select hidden states for action prediction tokens\n",
    "        a_hidden = hidden_states[:, 2::3]  # Assuming the actions are at these positions\n",
    "        \n",
    "        print(f\"a_hidden shape: {a_hidden.shape}\")\n",
    "\n",
    "        # Predict action\n",
    "        return self.predict_action(a_hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, returns, states, actions, timesteps):\n",
    "    print(f\"returns shape: {returns.shape}\")\n",
    "    print(f\"states shape: {states.shape}\")\n",
    "    print(f\"actions shape: {actions.shape}\")\n",
    "    print(f\"timesteps shape: {timesteps.shape}\")\n",
    "    \n",
    "    pos_embedding = self.embed_t(timesteps.long())\n",
    "    s_embedding = self.state_emb(states) + pos_embedding\n",
    "    a_embedding = self.action_emb(actions) + pos_embedding\n",
    "    R_embedding = self.reward_emb(returns.unsqueeze(-1)) + pos_embedding\n",
    "\n",
    "    print(f\"pos_embedding shape: {pos_embedding.shape}\")\n",
    "    print(f\"s_embedding shape: {s_embedding.shape}\")\n",
    "    print(f\"a_embedding shape: {a_embedding.shape}\")\n",
    "    print(f\"R_embedding shape: {R_embedding.shape}\")\n",
    "\n",
    "    # Interleave tokens as (R_1, s_1, a_1, ..., R_K, s_K)\n",
    "    input_embeds = torch.stack((R_embedding, s_embedding, a_embedding), dim=1).view(s_embedding.size(0), -1, s_embedding.size(-1))\n",
    "    \n",
    "    print(f\"input_embeds shape: {input_embeds.shape}\")\n",
    "    \n",
    "    # Use transformer to get hidden states\n",
    "    hidden_states = self.transformer(inputs_embeds=input_embeds).last_hidden_state\n",
    "    \n",
    "    print(f\"hidden_states shape: {hidden_states.shape}\")\n",
    "    \n",
    "    # Select hidden states for action prediction tokens\n",
    "    a_hidden = hidden_states[:, 2::3]  # Assuming the actions are at these positions\n",
    "    \n",
    "    print(f\"a_hidden shape: {a_hidden.shape}\")\n",
    "\n",
    "    # Predict action\n",
    "    return self.predict_action(a_hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 0, Loss: 6.664906978607178\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 1, Loss: 6.3777241706848145\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 2, Loss: 5.943504810333252\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 3, Loss: 6.439935684204102\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 4, Loss: 5.826087474822998\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 5, Loss: 5.825540065765381\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 6, Loss: 5.9486517906188965\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 7, Loss: 5.251259803771973\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 8, Loss: 5.174778461456299\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 9, Loss: 5.244668483734131\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 10, Loss: 5.27740478515625\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 11, Loss: 4.782567977905273\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 12, Loss: 4.99573278427124\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 13, Loss: 4.576929092407227\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 14, Loss: 4.511270046234131\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 15, Loss: 4.462234020233154\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 16, Loss: 4.209776878356934\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 17, Loss: 3.8518216609954834\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 18, Loss: 4.084937572479248\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 19, Loss: 3.780219316482544\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 20, Loss: 3.7214152812957764\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 21, Loss: 3.605900526046753\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 22, Loss: 3.3779304027557373\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 23, Loss: 3.4643001556396484\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 24, Loss: 3.2223730087280273\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 25, Loss: 3.22761607170105\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 26, Loss: 2.964524269104004\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 27, Loss: 2.93323016166687\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 28, Loss: 2.859863042831421\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 29, Loss: 2.890660047531128\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 30, Loss: 3.004037618637085\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 31, Loss: 2.790553092956543\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 32, Loss: 2.6812925338745117\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 33, Loss: 2.5911080837249756\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 34, Loss: 2.5477559566497803\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 35, Loss: 2.6058945655822754\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 36, Loss: 2.616100311279297\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 37, Loss: 2.544431447982788\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 38, Loss: 2.560946226119995\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 39, Loss: 2.4649741649627686\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 40, Loss: 2.395353078842163\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 41, Loss: 2.392577886581421\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 42, Loss: 2.5330138206481934\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 43, Loss: 2.2778141498565674\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 44, Loss: 2.3559019565582275\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 45, Loss: 2.3020665645599365\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 46, Loss: 2.386672019958496\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 47, Loss: 1.9409393072128296\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 48, Loss: 2.0971202850341797\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 49, Loss: 1.9800801277160645\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 50, Loss: 1.9944099187850952\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 51, Loss: 2.1183078289031982\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 52, Loss: 2.04236102104187\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 53, Loss: 1.9254251718521118\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 54, Loss: 1.9594568014144897\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 55, Loss: 1.8717231750488281\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 56, Loss: 1.8302645683288574\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 57, Loss: 1.9068092107772827\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 58, Loss: 1.8340123891830444\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 59, Loss: 1.8580902814865112\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 60, Loss: 1.8157752752304077\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 61, Loss: 1.8209877014160156\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 62, Loss: 1.7746080160140991\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 63, Loss: 1.7039610147476196\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 64, Loss: 1.7447338104248047\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 65, Loss: 1.7199602127075195\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 66, Loss: 1.7246602773666382\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 67, Loss: 1.6785353422164917\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 68, Loss: 1.630180835723877\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 69, Loss: 1.515985131263733\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 70, Loss: 1.593553900718689\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 71, Loss: 1.608605980873108\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 72, Loss: 1.5865840911865234\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 73, Loss: 1.5570164918899536\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 74, Loss: 1.6700764894485474\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 75, Loss: 1.5736756324768066\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 76, Loss: 1.5282083749771118\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 77, Loss: 1.5368520021438599\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 78, Loss: 1.4594584703445435\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 79, Loss: 1.5049548149108887\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 80, Loss: 1.5555309057235718\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 81, Loss: 1.3745800256729126\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 82, Loss: 1.349830985069275\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 83, Loss: 1.4386218786239624\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 84, Loss: 1.3822792768478394\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 85, Loss: 1.474562644958496\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 86, Loss: 1.3441147804260254\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 87, Loss: 1.455030083656311\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 88, Loss: 1.3308573961257935\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 89, Loss: 1.3460248708724976\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 90, Loss: 1.4258111715316772\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 91, Loss: 1.3321974277496338\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 92, Loss: 1.3027759790420532\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 93, Loss: 1.3576961755752563\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 94, Loss: 1.2874691486358643\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 95, Loss: 1.285589575767517\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 96, Loss: 1.2830950021743774\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 97, Loss: 1.2486084699630737\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 98, Loss: 1.268225073814392\n",
      "input_embeds shape: torch.Size([2, 36, 128])\n",
      "hidden_states shape: torch.Size([2, 36, 128])\n",
      "a_hidden shape: torch.Size([2, 12, 128])\n",
      "Epoch 99, Loss: 1.3623110055923462\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "dataset = TensorDataset(returns_tensor, states_tensor, actions_tensor, timesteps_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model = DecisionTransformer(state_dim=4, action_dim=2, hidden_dim=128)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(100):  # Number of epochs\n",
    "    for R_batch, s_batch, a_batch, t_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        a_preds = model(R_batch, s_batch, a_batch, t_batch)\n",
    "        loss = loss_fn(a_preds, a_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
