{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Example trajectories\n",
    "trajectories = [\n",
    "    [\n",
    "        ([50, 950], [950, 50], (4, 2), 50, [150, 950], [950, 150]),\n",
    "        ([150, 950], [950, 150], (4, 2), 30, [250, 950], [950, 250]),\n",
    "        ([250, 950], [950, 250], (0, 3), 0, [250, 950], [850, 250]),\n",
    "        ([250, 950], [850, 250], (1, 1), 20, [250, 850], [850, 150]),\n",
    "        ([250, 850], [850, 150], (0, 4), 0, [250, 850], [950, 150]),\n",
    "        ([250, 850], [950, 150], (1, 1), 20, [250, 750], [950, 50]),\n",
    "        ([250, 750], [950, 50], (4, 1), -100, [350, 750], [950, 50]),\n",
    "        ([350, 750], [950, 50], (1, 1), -80, [350, 650], [950, 50]),\n",
    "        ([350, 650], [950, 50], (4, 0), 10, [450, 650], [950, 50]),\n",
    "        ([450, 650], [950, 50], (4, 2), 30, [550, 650], [950, 150]),\n",
    "        ([550, 650], [950, 150], (2, 4), -70, [550, 750], [950, 150]),\n",
    "        ([550, 750], [950, 150], (0, 3), 0, [550, 750], [850, 150]),\n",
    "        # # Add more steps...\n",
    "    ],\n",
    "    # Add more trajectories...\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returns shape: (1, 12)\n",
      "states shape: (1, 12, 4)\n",
      "actions shape: (1, 12, 2)\n",
      "timesteps shape: (1, 12)\n",
      "returns_tensor shape: torch.Size([1, 12])\n",
      "states_tensor shape: torch.Size([1, 12, 4])\n",
      "actions_tensor shape: torch.Size([1, 12, 2])\n",
      "timesteps_tensor shape: torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "def preprocess_trajectories(trajectories):\n",
    "    returns, states, actions, timesteps = [], [], [], []\n",
    "    for traj in trajectories:\n",
    "        traj_returns = []\n",
    "        traj_states = []\n",
    "        traj_actions = []\n",
    "        traj_timesteps = []\n",
    "        for t, step in enumerate(traj):\n",
    "            state_uav1, state_uav2, action, reward, next_states, done = step\n",
    "            state = state_uav1 + state_uav2\n",
    "            traj_returns.append(reward)\n",
    "            traj_states.append(state)\n",
    "            traj_actions.append(list(action))\n",
    "            traj_timesteps.append(t)  # Generate timesteps as a sequence of integers\n",
    "        returns.append(traj_returns)\n",
    "        states.append(traj_states)\n",
    "        actions.append(traj_actions)\n",
    "        timesteps.append(traj_timesteps)\n",
    "    \n",
    "    returns_array = np.array(returns)\n",
    "    states_array = np.array(states)\n",
    "    actions_array = np.array(actions)\n",
    "    timesteps_array = np.array(timesteps)\n",
    "\n",
    "    print(f'returns shape: {returns_array.shape}')\n",
    "    print(f'states shape: {states_array.shape}')\n",
    "    print(f'actions shape: {actions_array.shape}')\n",
    "    print(f'timesteps shape: {timesteps_array.shape}')\n",
    "    \n",
    "    return returns_array, states_array, actions_array, timesteps_array\n",
    "\n",
    "# Preprocess the data\n",
    "returns, states, actions, timesteps = preprocess_trajectories(trajectories)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "returns_tensor = torch.tensor(returns, dtype=torch.float32)\n",
    "states_tensor = torch.tensor(states, dtype=torch.float32)\n",
    "actions_tensor = torch.tensor(actions, dtype=torch.float32)\n",
    "timesteps_tensor = torch.tensor(timesteps, dtype=torch.float32)\n",
    "\n",
    "print(f'returns_tensor shape: {returns_tensor.shape}')  # Expected: (num_trajectories, num_steps)\n",
    "print(f'states_tensor shape: {states_tensor.shape}')  # Expected: (num_trajectories, num_steps, state_dim)\n",
    "print(f'actions_tensor shape: {actions_tensor.shape}')  # Expected: (num_trajectories, num_steps, action_dim)\n",
    "print(f'timesteps_tensor shape: {timesteps_tensor.shape}')  # Expected: (num_trajectories, num_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returns shape: (2, 5)\n",
      "states shape: (2, 5, 2)\n",
      "actions shape: (2, 5, 2)\n",
      "timesteps shape: (2, 5)\n",
      "returns_to_go shape: (2, 5)\n",
      "returns_tensor shape: torch.Size([2, 5])\n",
      "states_tensor shape: torch.Size([2, 5, 2])\n",
      "actions_tensor shape: torch.Size([2, 5, 2])\n",
      "timesteps_tensor shape: torch.Size([2, 5])\n",
      "returns_to_go_tensor shape: torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Example trajectories\n",
    "# Each inner list is a sequence of (state, action, reward, next_state, done) tuples\n",
    "trajectories = [\n",
    "    [\n",
    "        ([1.0, 2.0], [0.1, 0.2], 1.0, [1.5, 2.5], False),\n",
    "        ([1.5, 2.5], [0.1, 0.2], 0.5, [2.0, 3.0], False),\n",
    "        ([2.0, 3.0], [0.1, 0.2], -1.0, [2.5, 3.5], True)\n",
    "    ],\n",
    "    [\n",
    "        ([0.5, 1.5], [0.2, 0.3], 1.5, [1.0, 2.0], False),\n",
    "        ([1.0, 2.0], [0.2, 0.3], -0.5, [1.5, 2.5], True)\n",
    "    ]\n",
    "]\n",
    "\n",
    "def preprocess_trajectories(trajectories, state_dim, action_dim, max_len):\n",
    "    returns, states, actions, timesteps = [], [], [], []\n",
    "    for traj in trajectories:\n",
    "        traj_returns = []\n",
    "        traj_states = []\n",
    "        traj_actions = []\n",
    "        traj_timesteps = []\n",
    "        for t, step in enumerate(traj):\n",
    "            state, action, reward, next_state, done = step\n",
    "            traj_returns.append(reward)\n",
    "            traj_states.append(state)\n",
    "            traj_actions.append(action)\n",
    "            traj_timesteps.append(t)\n",
    "        \n",
    "        # Pad sequences to the maximum length\n",
    "        while len(traj_returns) < max_len:\n",
    "            traj_returns.append(0.0)  # Assuming padding with 0 for rewards\n",
    "            traj_states.append([0.0] * state_dim)  # Assuming padding with 0 for states\n",
    "            traj_actions.append([0.0] * action_dim)  # Assuming padding with 0 for actions\n",
    "            traj_timesteps.append(0)  # Assuming padding with 0 for timesteps\n",
    "        \n",
    "        returns.append(traj_returns)\n",
    "        states.append(traj_states)\n",
    "        actions.append(traj_actions)\n",
    "        timesteps.append(traj_timesteps)\n",
    "    \n",
    "    returns_array = np.array(returns)\n",
    "    states_array = np.array(states)\n",
    "    actions_array = np.array(actions)\n",
    "    timesteps_array = np.array(timesteps)\n",
    "    \n",
    "    # Calculate returns-to-go\n",
    "    returns_to_go = []\n",
    "    for traj in returns_array:\n",
    "        traj_returns_to_go = np.flip(np.cumsum(np.flip(traj, axis=0)), axis=0)\n",
    "        returns_to_go.append(traj_returns_to_go)\n",
    "    \n",
    "    returns_to_go_array = np.array(returns_to_go)\n",
    "    \n",
    "    print(f'returns shape: {returns_array.shape}')\n",
    "    print(f'states shape: {states_array.shape}')\n",
    "    print(f'actions shape: {actions_array.shape}')\n",
    "    print(f'timesteps shape: {timesteps_array.shape}')\n",
    "    print(f'returns_to_go shape: {returns_to_go_array.shape}')\n",
    "    \n",
    "    return returns_array, states_array, actions_array, timesteps_array, returns_to_go_array\n",
    "\n",
    "# Define the dimensions and maximum length\n",
    "state_dim = 2\n",
    "action_dim = 2\n",
    "max_len = 5  # Assuming a maximum length of 5 for simplicity\n",
    "\n",
    "# Preprocess the data\n",
    "returns, states, actions, timesteps, returns_to_go = preprocess_trajectories(trajectories, state_dim, action_dim, max_len)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "returns_tensor = torch.tensor(returns, dtype=torch.float32)\n",
    "states_tensor = torch.tensor(states, dtype=torch.float32)\n",
    "actions_tensor = torch.tensor(actions, dtype=torch.float32)\n",
    "timesteps_tensor = torch.tensor(timesteps, dtype=torch.float32)\n",
    "returns_to_go_tensor = torch.tensor(returns_to_go, dtype=torch.float32)\n",
    "\n",
    "print(f'returns_tensor shape: {returns_tensor.shape}')\n",
    "print(f'states_tensor shape: {states_tensor.shape}')\n",
    "print(f'actions_tensor shape: {actions_tensor.shape}')\n",
    "print(f'timesteps_tensor shape: {timesteps_tensor.shape}')\n",
    "print(f'returns_to_go_tensor shape: {returns_to_go_tensor.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steve\\anaconda3\\envs\\ml_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "add_code_sample_docstrings() got an unexpected keyword argument 'tokenizer_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdecision_transformer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrajectoryModel\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdecision_transformer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrajectory_gpt2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2Model\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDecisionTransformer\u001b[39;00m(TrajectoryModel):\n\u001b[0;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    This model uses GPT to model (Return_1, state_1, action_1, Return_2, state_2, ...)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\steve\\OneDrive\\Desktop\\AI _PROJECT_ UAV\\decision_transformer\\models\\trajectory_gpt2.py:516\u001b[0m\n\u001b[0;32m    476\u001b[0m PARALLELIZE_DOCSTRING \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;124m    Uses a device map to distribute attention modules of the model across several devices. If no device map is given,\u001b[39m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;124m    it will evenly distribute blocks across all devices.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;124m            model.parallelize(device_map)\u001b[39m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    498\u001b[0m DEPARALLELIZE_DOCSTRING \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;124m    Moves the model to cpu from a model parallel state.\u001b[39m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;124m    Example::\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124m        model.deparallelize() # Put the model back on cpu and cleans memory by calling torch.cuda.empty_cache()\u001b[39m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;129m@add_start_docstrings\u001b[39m(\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe bare GPT2 Model transformer outputting raw hidden-states without any specific head on top.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    514\u001b[0m     GPT2_START_DOCSTRING,\n\u001b[0;32m    515\u001b[0m )\n\u001b[1;32m--> 516\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGPT2Model\u001b[39;00m(GPT2PreTrainedModel):\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[0;32m    518\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n",
      "File \u001b[1;32mc:\\Users\\steve\\OneDrive\\Desktop\\AI _PROJECT_ UAV\\decision_transformer\\models\\trajectory_gpt2.py:586\u001b[0m, in \u001b[0;36mGPT2Model\u001b[1;34m()\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer, heads \u001b[38;5;129;01min\u001b[39;00m heads_to_prune\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    583\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh[layer]\u001b[38;5;241m.\u001b[39mattn\u001b[38;5;241m.\u001b[39mprune_heads(heads)\n\u001b[0;32m    585\u001b[0m \u001b[38;5;129m@add_start_docstrings_to_model_forward\u001b[39m(GPT2_INPUTS_DOCSTRING)\n\u001b[1;32m--> 586\u001b[0m \u001b[38;5;129m@add_code_sample_docstrings\u001b[39m\u001b[43m(\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_TOKENIZER_FOR_DOC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBaseModelOutputWithPastAndCrossAttentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_CONFIG_FOR_DOC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    593\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    594\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    595\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    596\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    597\u001b[0m         token_type_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    598\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    599\u001b[0m         head_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    600\u001b[0m         inputs_embeds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    601\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    602\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    603\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    604\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    605\u001b[0m         output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    606\u001b[0m         return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    607\u001b[0m ):\n\u001b[0;32m    608\u001b[0m     output_attentions \u001b[38;5;241m=\u001b[39m output_attentions \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_attentions\n\u001b[0;32m    609\u001b[0m     output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    610\u001b[0m         output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[0;32m    611\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: add_code_sample_docstrings() got an unexpected keyword argument 'tokenizer_class'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import activations\n",
    "\n",
    "from decision_transformer.models.model import TrajectoryModel\n",
    "from decision_transformer.models.trajectory_gpt2 import GPT2Model\n",
    "\n",
    "\n",
    "class DecisionTransformer(TrajectoryModel):\n",
    "\n",
    "    \"\"\"\n",
    "    This model uses GPT to model (Return_1, state_1, action_1, Return_2, state_2, ...)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            state_dim,\n",
    "            act_dim,\n",
    "            hidden_size,\n",
    "            max_length=None,\n",
    "            max_ep_len=4096,\n",
    "            action_tanh=True,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__(state_dim, act_dim, max_length=max_length)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        config = transformers.GPT2Config(\n",
    "            vocab_size=1,  # doesn't matter -- we don't use the vocab\n",
    "            n_embd=hidden_size,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # note: the only difference between this GPT2Model and the default Huggingface version\n",
    "        # is that the positional embeddings are removed (since we'll add those ourselves)\n",
    "        self.transformer = GPT2Model(config)\n",
    "\n",
    "        self.embed_timestep = nn.Embedding(max_ep_len, hidden_size)\n",
    "        self.embed_return = torch.nn.Linear(1, hidden_size)\n",
    "        self.embed_state = torch.nn.Linear(self.state_dim, hidden_size)\n",
    "        self.embed_action = torch.nn.Linear(self.act_dim, hidden_size)\n",
    "\n",
    "        self.embed_ln = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        # note: we don't predict states or returns for the paper\n",
    "        self.predict_state = torch.nn.Linear(hidden_size, self.state_dim)\n",
    "        self.predict_action = nn.Sequential(\n",
    "            *([nn.Linear(hidden_size, self.act_dim)] + ([nn.Tanh()] if action_tanh else []))\n",
    "        )\n",
    "        self.predict_return = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, states, actions, rewards, returns_to_go, timesteps, attention_mask=None):\n",
    "\n",
    "        batch_size, seq_length = states.shape[0], states.shape[1]\n",
    "\n",
    "        if attention_mask is None:\n",
    "            # attention mask for GPT: 1 if can be attended to, 0 if not\n",
    "            attention_mask = torch.ones((batch_size, seq_length), dtype=torch.long)\n",
    "\n",
    "        # embed each modality with a different head\n",
    "        state_embeddings = self.embed_state(states)\n",
    "        action_embeddings = self.embed_action(actions)\n",
    "        returns_embeddings = self.embed_return(returns_to_go)\n",
    "        time_embeddings = self.embed_timestep(timesteps)\n",
    "\n",
    "        # time embeddings are treated similar to positional embeddings\n",
    "        state_embeddings = state_embeddings + time_embeddings\n",
    "        action_embeddings = action_embeddings + time_embeddings\n",
    "        returns_embeddings = returns_embeddings + time_embeddings\n",
    "\n",
    "        # this makes the sequence look like (R_1, s_1, a_1, R_2, s_2, a_2, ...)\n",
    "        # which works nice in an autoregressive sense since states predict actions\n",
    "        stacked_inputs = torch.stack(\n",
    "            (returns_embeddings, state_embeddings, action_embeddings), dim=1\n",
    "        ).permute(0, 2, 1, 3).reshape(batch_size, 3*seq_length, self.hidden_size)\n",
    "        stacked_inputs = self.embed_ln(stacked_inputs)\n",
    "\n",
    "        # to make the attention mask fit the stacked inputs, have to stack it as well\n",
    "        stacked_attention_mask = torch.stack(\n",
    "            (attention_mask, attention_mask, attention_mask), dim=1\n",
    "        ).permute(0, 2, 1).reshape(batch_size, 3*seq_length)\n",
    "\n",
    "        # we feed in the input embeddings (not word indices as in NLP) to the model\n",
    "        transformer_outputs = self.transformer(\n",
    "            inputs_embeds=stacked_inputs,\n",
    "            attention_mask=stacked_attention_mask,\n",
    "        )\n",
    "        x = transformer_outputs['last_hidden_state']\n",
    "\n",
    "        # reshape x so that the second dimension corresponds to the original\n",
    "        # returns (0), states (1), or actions (2); i.e. x[:,1,t] is the token for s_t\n",
    "        x = x.reshape(batch_size, seq_length, 3, self.hidden_size).permute(0, 2, 1, 3)\n",
    "\n",
    "        # get predictions\n",
    "        return_preds = self.predict_return(x[:,2])  # predict next return given state and action\n",
    "        state_preds = self.predict_state(x[:,2])    # predict next state given state and action\n",
    "        action_preds = self.predict_action(x[:,1])  # predict next action given state\n",
    "\n",
    "        return state_preds, action_preds, return_preds\n",
    "\n",
    "    def get_action(self, states, actions, rewards, returns_to_go, timesteps, **kwargs):\n",
    "        # we don't care about the past rewards in this model\n",
    "\n",
    "        states = states.reshape(1, -1, self.state_dim)\n",
    "        actions = actions.reshape(1, -1, self.act_dim)\n",
    "        returns_to_go = returns_to_go.reshape(1, -1, 1)\n",
    "        timesteps = timesteps.reshape(1, -1)\n",
    "\n",
    "        if self.max_length is not None:\n",
    "            states = states[:,-self.max_length:]\n",
    "            actions = actions[:,-self.max_length:]\n",
    "            returns_to_go = returns_to_go[:,-self.max_length:]\n",
    "            timesteps = timesteps[:,-self.max_length:]\n",
    "\n",
    "            # pad all tokens to sequence length\n",
    "            attention_mask = torch.cat([torch.zeros(self.max_length-states.shape[1]), torch.ones(states.shape[1])])\n",
    "            attention_mask = attention_mask.to(dtype=torch.long, device=states.device).reshape(1, -1)\n",
    "            states = torch.cat(\n",
    "                [torch.zeros((states.shape[0], self.max_length-states.shape[1], self.state_dim), device=states.device), states],\n",
    "                dim=1).to(dtype=torch.float32)\n",
    "            actions = torch.cat(\n",
    "                [torch.zeros((actions.shape[0], self.max_length - actions.shape[1], self.act_dim),\n",
    "                             device=actions.device), actions],\n",
    "                dim=1).to(dtype=torch.float32)\n",
    "            returns_to_go = torch.cat(\n",
    "                [torch.zeros((returns_to_go.shape[0], self.max_length-returns_to_go.shape[1], 1), device=returns_to_go.device), returns_to_go],\n",
    "                dim=1).to(dtype=torch.float32)\n",
    "            timesteps = torch.cat(\n",
    "                [torch.zeros((timesteps.shape[0], self.max_length-timesteps.shape[1]), device=timesteps.device), timesteps],\n",
    "                dim=1\n",
    "            ).to(dtype=torch.long)\n",
    "        else:\n",
    "            attention_mask = None\n",
    "\n",
    "        _, action_preds, return_preds = self.forward(\n",
    "            states, actions, None, returns_to_go, timesteps, attention_mask=attention_mask, **kwargs)\n",
    "\n",
    "        return action_preds[0,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m max_ep_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m  \u001b[38;5;66;03m# Maximum episode length\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Instantiate the model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m DecisionTransformer(state_dim\u001b[38;5;241m=\u001b[39mstate_dim, act_dim\u001b[38;5;241m=\u001b[39maction_dim, hidden_size\u001b[38;5;241m=\u001b[39mhidden_size, max_length\u001b[38;5;241m=\u001b[39mmax_length, max_ep_len\u001b[38;5;241m=\u001b[39mmax_ep_len)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Forward pass through the model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m state_preds, action_preds, return_preds \u001b[38;5;241m=\u001b[39m model(\n\u001b[0;32m     11\u001b[0m     states\u001b[38;5;241m=\u001b[39mstates_tensor,\n\u001b[0;32m     12\u001b[0m     actions\u001b[38;5;241m=\u001b[39mactions_tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     timesteps\u001b[38;5;241m=\u001b[39mtimesteps_tensor\n\u001b[0;32m     16\u001b[0m )\n",
      "Cell \u001b[1;32mIn[32], line 33\u001b[0m, in \u001b[0;36mDecisionTransformer.__init__\u001b[1;34m(self, state_dim, act_dim, hidden_size, max_length, max_ep_len, action_tanh, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m config \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mGPT2Config(\n\u001b[0;32m     26\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# doesn't matter -- we don't use the vocab\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     n_embd\u001b[38;5;241m=\u001b[39mhidden_size,\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# note: the only difference between this GPT2Model and the default Huggingface version\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# is that the positional embeddings are removed (since we'll add those ourselves)\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer \u001b[38;5;241m=\u001b[39m GPT2Model(config)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_timestep \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(max_ep_len, hidden_size)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_return \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m1\u001b[39m, hidden_size)\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\Lib\\site-packages\\transformers\\modeling_gpt2.py:355\u001b[0m, in \u001b[0;36mGPT2Model.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwpe \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mn_positions, config\u001b[38;5;241m.\u001b[39mn_embd)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39membd_pdrop)\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([Block(config\u001b[38;5;241m.\u001b[39mn_ctx, config, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mn_layer)])\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_f \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(config\u001b[38;5;241m.\u001b[39mn_embd, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_epsilon)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_weights()\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\Lib\\site-packages\\transformers\\modeling_gpt2.py:355\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwpe \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mn_positions, config\u001b[38;5;241m.\u001b[39mn_embd)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39membd_pdrop)\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([Block(config\u001b[38;5;241m.\u001b[39mn_ctx, config, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mn_layer)])\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_f \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(config\u001b[38;5;241m.\u001b[39mn_embd, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_epsilon)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_weights()\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\Lib\\site-packages\\transformers\\modeling_gpt2.py:223\u001b[0m, in \u001b[0;36mBlock.__init__\u001b[1;34m(self, n_ctx, config, scale)\u001b[0m\n\u001b[0;32m    221\u001b[0m nx \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mn_embd\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(nx, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_epsilon)\n\u001b[1;32m--> 223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn \u001b[38;5;241m=\u001b[39m Attention(nx, n_ctx, config, scale)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(nx, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_epsilon)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m MLP(\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m nx, config)\n",
      "File \u001b[1;32mc:\\Users\\steve\\anaconda3\\Lib\\site-packages\\transformers\\modeling_gpt2.py:109\u001b[0m, in \u001b[0;36mAttention.__init__\u001b[1;34m(self, nx, n_ctx, config, scale)\u001b[0m\n\u001b[0;32m    107\u001b[0m n_state \u001b[38;5;241m=\u001b[39m nx  \u001b[38;5;66;03m# in Attention: n_state=768 (nx=n_embd)\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# [switch nx => n_state from Block to Attention to keep identical to TF implem]\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m n_state \u001b[38;5;241m%\u001b[39m config\u001b[38;5;241m.\u001b[39mn_head \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtril(torch\u001b[38;5;241m.\u001b[39mones(n_ctx, n_ctx))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, n_ctx, n_ctx))\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_head \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mn_head\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example input data dimensions\n",
    "hidden_size = 128  # Hidden size for the transformer\n",
    "max_length = 50  # Maximum sequence length\n",
    "max_ep_len = 4096  # Maximum episode length\n",
    "\n",
    "# Instantiate the model\n",
    "model = DecisionTransformer(state_dim=state_dim, act_dim=action_dim, hidden_size=hidden_size, max_length=max_length, max_ep_len=max_ep_len)\n",
    "\n",
    "# Forward pass through the model\n",
    "state_preds, action_preds, return_preds = model(\n",
    "    states=states_tensor,\n",
    "    actions=actions_tensor,\n",
    "    rewards=None,\n",
    "    returns_to_go=returns_to_go_tensor,\n",
    "    timesteps=timesteps_tensor\n",
    ")\n",
    "\n",
    "print(f'action_preds: {action_preds}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
